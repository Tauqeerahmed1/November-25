"Student: Tauqeer Ahmed;        Supervisor: Dr. Madiha Yousaf;      Research Area: ML-Recommender Systems/ NLP
Proposed Research: Reimagining the Press Release Distribution Industry in the Age of Generative AI: 
Challenges, Limitations, and an AI-Powered Roadmap — A Case Study of Evertise Ai PR Inc. https://evertise.net",,,,,,,,,,,
Year,Author,Paper Name,What are they doing,"Model
(Novel/
Hybrid)",Advantages,Limitations,Dataset,Algorithm,"Impact Factor/
Journal",Acronym Expansions,URLs,Pain points,Application to PR
2009,"Base Paper

Yehuda Koren; Robert Bell; Chris Volinsky",Matrix Factorization Techniques for Recommender Systems,"Present and evaluate matrix factorization latent-factor methods for collaborative filtering; discuss biases, temporal dynamics, and training approaches.",Novel,High accuracy for rating prediction; effective latent-factor representations; scalable to large datasets; handles sparsity well.,Cold-start for new users/items; less interpretable latent factors; requires substantial data and tuning; standard MF handles explicit feedback best.,Netflix Prize dataset,"Matrix Factorization (SVD variants, SVD++, ALS, SGD), temporal extensions","Computer (IEEE Computer Society), 2009; highly influential",SVD: Singular Value Decomposition; SVD++: SVD with implicit-feedback extension (Koren's SVD++); ALS: Alternating Least Squares; SGD: Stochastic Gradient Descent; MF: Matrix Factorization,https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf,"Package selection","Use MF as a baseline to learn latent mappings between PR content/outlet engagement and rank outlets; combine with cold-start methods for new clients/outlets."
2021,Hanxiong Chen; Shaoyun Shi; Yunqi Li; Yongfeng Zhang,Neural Collaborative Reasoning,Propose Neural Collaborative Reasoning (NCR): integrate neural representation learning with symbolic logical reasoning by dynamically assembling neural modules that implement logical operations (AND/OR/NOT) and Horn-clause implication for recommendation.,Novel (neural+symbolic hybrid),"Combines pattern learning with logical reasoning; improves ranking (NDCG/HR); modular, interpretable reasoning structure; competitive across baselines.",Higher model complexity and runtime; requires careful logical regularization and sufficient data; added design/training complexity for logical modules.,"ML100k; Amazon (Movies & TV, Electronics)","Neural logic modules (AND/OR/NOT), Horn-clause implication reasoning, pairwise negative-sampling training, logical regularizers; compared with BPR-MF, SVD++, DMF, NeuMF, GRU4Rec, STAMP, NLR","WWW '21 (The Web Conference), 2021; pages 1516-1527; DOI:10.1145/3442381.3449973","AND: logical AND; OR: logical OR; NOT: logical NOT; Horn clause: (logic term, not an acronym); BPR: Bayesian Personalized Ranking; BPR-MF: BPR with Matrix Factorization; SVD++: SVD with implicit-feedback extension; DMF: Deep Matrix Factorization; NeuMF: Neural Matrix Factorization (Neural Collaborative Filtering); GRU4Rec: Gated Recurrent Unit for Recommendation; STAMP: Short-Term Attention/Memory Priority model; NLR: Neural Logic Reasoning; NCR: Neural Collaborative Reasoning; ML100k: MovieLens 100k; NDCG: Normalized Discounted Cumulative Gain; HR: Hit Ratio",https://dl.acm.org/doi/pdf/10.1145/3442381.3449973,"Package selection","Apply logical constraints (e.g., industry AND region) over learned preferences to ensure outlet lists match PR intent and compliance rules."
2021,"Dang-Dat Tran, Le-Thanh Nguyen-Huynh, Quang-Vinh Nguyen","A Survey of Visual Analytics for Explainable Artificial Intelligence","Provides a comprehensive overview of Visual Analytics (VA) for Explainable Artificial Intelligence (XAI), focusing on how visualization and interaction can improve model transparency and interpretability.",Survey,"VA provides intuitive and interactive visualizations to help users understand the behavior of complex AI models, bridging the gap between complex explanations and user comprehension.","Many existing XAI methods produce explanations that are difficult for end-users to understand, limiting their practical utility.",,"Taxonomy-based review","Computer Graphics Forum","XAI: Explainable Artificial Intelligence; VA: Visual Analytics","https://doi.org/10.1111/cgf.14301",,
2023,Elizabeth Reid,Supercharging Search with generative AI,"Announces Google's Search Generative Experience (SGE) introducing AI-powered snapshots and conversational follow-ups; highlights how search will surface summarized answers with links, changing how content must be structured for discoverability (AEO implications).",Industry announcement,"Explains AI snapshots, shows continued linking to sources; signals importance of structured, semantically rich content for visibility in AI-driven search.",Not peer-reviewed; experimental rollout and limited availability at launch.,N/A,Generative AI in Google Search (undisclosed),Google Keyword Blog (May 10, 2023),"SGE: Search Generative Experience; AEO: Answer Engine Optimization",https://blog.google/products/search/generative-ai-search/,"Content optimization","Structure PRs for AI snapshots with concise headings, context, quality signals, and links; add schema to aid discoverability."
2023,Yang Li; Kangbo Liu; Ranjan Satapathy; Suhang Wang; Erik Cambria,Recent Developments in Recommender Systems: A Survey,"Surveys recent advances in recommender systems (deep models, sequential/graph-based and transformer-based recommenders), covering architectures and evaluation; applicable to data-driven selection of distribution outlets.",Survey,"Comprehensive overview of state-of-the-art RS methods; identifies models useful for relevance matching and multi-stage ranking.",General-purpose survey; not PR-specific; limited discussion of outlet-level constraints.,Various public benchmarks (as surveyed),Deep learning–based recommenders (e.g., GNNs, transformers, multi-stage ranking),arXiv preprint,"GNN: Graph Neural Network; CTR: Click-Through Rate",https://arxiv.org/abs/2306.12680,"Package selection","Select and evaluate deep ranking architectures (GNNs/Transformers) for content-to-outlet matching and multi-stage PR distribution."
2023,Peiyan Zhang; Sunghun Kim,A Survey on Incremental Update for Neural Recommender Systems,"Reviews incremental/online learning techniques to keep recommender models fresh without full retraining; relevant for continuously updating content-to-outlet mapping based on new performance data.",Survey,"Addresses non-stationarity and freshness; summarizes efficient update strategies for production recommenders.",Focuses on update mechanics rather than domain-specific objectives like PR distribution.,Various public benchmarks (as surveyed),Incremental/online learning for RS; streaming updates; model adaptation,arXiv preprint,OL: Online Learning,https://arxiv.org/abs/2303.02851,"Package selection","Deploy online updating to reflect outlet performance drift and news-cycle shifts without full retraining of the recommender."
2023,Zefeng Chen; Wensheng Gan; Jiayang Wu; Kaixia Hu; Hong Lin,Data Scarcity in Recommendation Systems: A Survey,"Analyzes cold-start and data sparsity challenges in recommendation, reviewing transfer/meta-learning and augmentation approaches; relevant to sparse interactions between press releases and outlets.",Survey,"Systematic taxonomy of data-scarcity solutions; guidance to mitigate cold-start when choosing outlets with limited history.",Survey scope; limited application specifics for PR.,Various public benchmarks (as surveyed),Cold-start and data augmentation methods for RS,arXiv preprint (ACM TORS, preprint),"Cold-start: initial lack of interactions; TORS: Transactions on Recommender Systems",https://arxiv.org/abs/2312.10073,"Package selection","Apply transfer/meta-learning and augmentation to handle new clients or niche outlets with little interaction history."
2024,Qidong Liu; Xiangyu Zhao; Yuhao Wang; Yejing Wang; Zijian Zhang; Yuqi Sun; Xiang Li; Maolin Wang; Pengyue Jia; Chong Chen; Wei Huang; Feng Tian,Large Language Model Enhanced Recommender Systems: A Survey,"Surveys integration of large language models (LLMs) into recommender systems (prompting, RAG, generation, agentic RS); informs data-driven package recommendations by leveraging semantic understanding of content and outlets.",Survey,"Covers LLM-augmented candidate generation/reranking and explainability; highlights zero/few-shot matching opportunities.",Preprint; limited availability of standardized benchmarks for LLM-RS.,Various public benchmarks (as surveyed),LLM-augmented RS (prompting, RAG, re-ranking),arXiv preprint,"LLM: Large Language Model; RAG: Retrieval-Augmented Generation",https://arxiv.org/abs/2412.13432,"Content optimization; Package selection","Use LLM embeddings and prompts to match PR semantics to outlet topics and generate explainable, tailored distribution lists."
2025,Google Search Central,Creating helpful, reliable, people-first content,"Official guidance for creating high-quality content aligned with E-E-A-T; includes advice on AI-generated content disclosures and structured data—actionable for optimizing PR content discoverability in AI-driven search.",Guidance/Best practices,"Actionable checklist (E-E-A-T, page experience, structured data); authoritative and frequently updated.",Not peer-reviewed; search-engine specific guidance.,N/A,N/A,Google Search Central Documentation (last updated 2025-09-22),"E-E-A-T: Experience, Expertise, Authoritativeness, Trustworthiness",https://developers.google.com/search/docs/fundamentals/creating-helpful-content,"Content optimization","Apply E-E-A-T and NewsArticle/Organization structured data; ensure bylines, disclosures, and page experience to improve AI/AEO visibility."
2025,Google Search Central,Google Search's guidance on using generative AI content on your website,"Guidance on using AI-generated content responsibly for the web; emphasizes accuracy, relevance, structured data, and providing context about how AI was used—relevant to AI-assisted PR content workflows.",Guidance/Best practices,"Clarifies policies on scaled content abuse and best practices for metadata/structured data; aligns AI content with Search Essentials.",Not peer-reviewed; focused on Search policies.,N/A,N/A,Google Search Central Documentation (last updated 2025-05-21),"AI: Artificial Intelligence; IPTC TrainedAlgorithmicMedia: metadata value for AI images",https://developers.google.com/search/docs/fundamentals/using-gen-ai-content,"Content optimization","Disclose AI assistance, ensure accurate metadata and structured data, and validate markup to maintain visibility and avoid spam-policy issues."
2024,"Yiquan An; Yingxin Tan; Xi Sun; Giovannipaolo Ferrari",Recommender System: A Comprehensive Overview of Technical Challenges and Social Implications,"Comprehensive review of recommender systems' technical paradigms (collaborative filtering, scenario-aware, knowledge & data co-driven, LLM-based, hybrid) and social implications; identifies challenges (accuracy, cold-start, explainability, privacy) and research gaps; relevant for data-driven media outlet/package selection and content optimization.",Survey,"Integrates technical and sociological perspectives; clear taxonomy including LLM-based approaches; highlights gaps for fairness and transparency.",Not PR-specific; no new empirical benchmarks; limited domain-specific guidance for press distribution.,Various cited works; no primary dataset,"CF; scenario-aware; knowledge/data co-driven; LLM-augmented; hybrid methods","ICCK Transactions on Sensing, Communication, and Control, 1(1):30–51 (2024); DOI:10.62762/TSCC.2024.898503","RecSys: Recommender Systems; LLM: Large Language Model; CF: Collaborative Filtering",https://www.icck.org/article/abs/tscc.2024.898503,"Package selection; Content optimization","Use the survey's taxonomy to design outlet-matching (CNMM) and bake fairness/explainability into distribution and messaging strategies."
2024,"Jiahao Tian; Jinman Zhao; Zhenkai Wang; Zhicheng Ding",MMREC: LLM Based Multi-Modal Recommender System,"Proposes MMREC, a large-language-model-based multi-modal recommender that integrates text and image signals into a unified latent space to improve ranking relevance; demonstrates enhanced discriminative power from multi-modal fusion.",Novel (LLM + multi-modal hybrid),"Leverages LLM semantic understanding; unifies modalities; improves accuracy and relevance—useful for mapping PR content (text/images) to outlet/audience fit.",ArXiv preprint; domain-agnostic (not PR-specific); datasets and compute requirements not detailed on abstract page.,Not stated on abstract page (see PDF),LLM-augmented multi-modal embedding + ranking,"arXiv preprint (cs.CL; cs.IR), v2 revised 2025-06-11",LLM: Large Language Model; MMREC: Multi-Modal Recommender,https://arxiv.org/abs/2408.04211,"Content optimization; Package selection","Fuse PR text and visuals in a unified embedding to better target outlets and audiences, improving relevance and downstream pickup."
2025,Lylla Aslam,How to Measure the Success of a Press Release: The Metrics That Matter.,"Provides a practical framework and KPIs for measuring PR performance across reach/impressions, CTR and engagement, media pickups/mentions, sentiment analysis, website traffic/conversions (with UTMs), social signals, and journalist engagement; includes guidance on aligning metrics to goals and communicating ROI (e.g., EMV).",Guidance/Best practices,"Actionable, goal-aligned metrics covering awareness to conversion; emphasizes sentiment and media quality; executive-friendly ROI framing.",Company blog; not peer-reviewed; no standardized benchmarks or datasets; potential publication bias.,N/A,N/A,Evertise Blog,"CTR: Click-Through Rate; EMV: Earned Media Value; KPI: Key Performance Indicator; UTM: Urchin Tracking Module",https://evertise.net/blog-post/how-to-measure-the-success-of-a-press-release-the-metrics-that-matter/,"Package selection; Content optimization","Instrument PRs with UTM tracking and monitor pickups, sentiment, and engagement to evaluate outlet/package performance and to iteratively optimize content and targeting."
2025,"Fali Wang, Minhua Lin, Yao Ma, Hui Liu, Qi He, Xianfeng Tang","A Survey on Small Language Models in the Era of Large Language Models: Architecture, Capabilities, and Trustworthiness","Surveying the landscape of Small Language Models (SLMs) as alternatives or assistants to Large Language Models (LLMs), covering architectures (like Mamba, xLSTM), performance strategies, and their role in enhancing LLM efficiency and security.",Survey,"SLMs offer reduced deployment costs, lower inference latency, and can scale linearly, addressing key limitations of LLMs. They can also assist LLMs in tasks like proxy tuning and safety guarding.","The trustworthiness of SLMs is a significant, underexplored area of research.",,"Mamba, xLSTM, Transformers","KDD '25: Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.2","SLM: Small Language Model; LLM: Large Language Model; KDD: Knowledge Discovery and Data Mining","https://doi.org/10.1145/3711896.3736563",,
2025,"Li Li","Ai for Content Generation: Automating Journalism, Art, and Media Production","Examining the use of AI in media for content creation, editing, and distribution. It compares the performance of different AI algorithms (CO-EBFGS, RNN, CNN, etc.) for content generation tasks.",Hybrid,"The CO-EBFGS model demonstrated superior accuracy (91.2%) and reliability for AI-driven content generation compared to traditional models like RNN and CNN.","The increasing reliance on AI raises ethical issues such as algorithmic bias, lack of transparency, and a potential decline in journalistic integrity.",,"CO-EBFGS, RNN, CNN, Naive Bayes, Logistic Regression","SSRN Electronic Journal","AI: Artificial Intelligence; CO-EBFGS: (not specified); RNN: Recurrent Neural Network; CNN: Convolutional Neural Network","https://doi.org/10.2139/ssrn.5179509",,
2021,"Dang-Dat Tran, Le-Thanh Nguyen-Huynh, Quang-Vinh Nguyen","A Survey of Visual Analytics for Explainable Artificial Intelligence","Provides a comprehensive overview of Visual Analytics (VA) for Explainable Artificial Intelligence (XAI), focusing on how visualization and interaction can improve model transparency and interpretability.",Survey,"VA provides intuitive and interactive visualizations to help users understand the behavior of complex AI models, bridging the gap between complex explanations and user comprehension.","Many existing XAI methods produce explanations that are difficult for end-users to understand, limiting their practical utility.",,"Taxonomy-based review","Computer Graphics Forum","XAI: Explainable Artificial Intelligence; VA: Visual Analytics","https://doi.org/10.1111/cgf.14301",,